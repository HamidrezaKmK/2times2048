{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "training.ipynb",
      "provenance": [],
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/HamidrezaKmK/2times2048/blob/master/training.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Prerequisites"
      ],
      "metadata": {
        "id": "hJK52DMK62tQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Git\n",
        "# SETUP GIT\n",
        "!git clone https://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@github.com/HamidrezaKmK/DrugCombination\n",
        "\n",
        "# Uncomment to pull \n",
        "#%cd /content/DrugCombination\n",
        "#!git pull"
      ],
      "metadata": {
        "id": "1mcybFjg64AR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "245c715d-f714-4680-b0e4-71b45eb3d58d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'DrugCombination'...\n",
            "remote: Enumerating objects: 179, done.\u001b[K\n",
            "remote: Counting objects: 100% (179/179), done.\u001b[K\n",
            "remote: Compressing objects: 100% (159/159), done.\u001b[K\n",
            "remote: Total 179 (delta 80), reused 50 (delta 16), pack-reused 0\u001b[K\n",
            "Receiving objects: 100% (179/179), 2.67 MiB | 11.42 MiB/s, done.\n",
            "Resolving deltas: 100% (80/80), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KaD9gBg8VA9c",
        "outputId": "e8cacfd8-423b-48c1-8b92-05fbb2004d63",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "# Import drive \n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#!pip uninstall torch -y\n",
        "!pip install torch==1.10.0+cu111 -f https://download.pytorch.org/whl/cu111/torch_stable.html\n",
        "!pip install rdkit-pypi\n",
        "!pip install networkx\n",
        "!pip install --no-index torch-sparse -f https://pytorch-geometric.com/whl/torch-1.10.0+cu111.html\n",
        "!pip install --no-index torch-cluster -f https://pytorch-geometric.com/whl/torch-1.10.0+cu111.html\n",
        "!pip install --no-index torch-spline-conv -f https://pytorch-geometric.com/whl/torch-1.10.0+cu111.html\n",
        "!pip install --no-index torch-scatter -f https://pytorch-geometric.com/whl/torch-1.10.0+cu111.html\n",
        "!pip install torch-geometric\n",
        "!pip install class-resolver"
      ],
      "metadata": {
        "id": "PG5l8cSUc_Yr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!nvidia-smi"
      ],
      "metadata": {
        "id": "QKUPeoTUBcBX",
        "outputId": "1b460bb2-473f-4ef3-c65a-df8480dd292f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sun May 22 12:49:40 2022       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 460.32.03    Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla P100-PCIE...  Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   36C    P0    28W / 250W |      0MiB / 16280MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tqdm import tqdm\n",
        "import pickle\n",
        "import pandas as pd\n",
        "import os\n",
        "import numpy as np\n",
        "from IPython.display import clear_output\n",
        "import math\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from typing import List\n",
        "from torch.utils.data import Dataset, DataLoader, SubsetRandomSampler\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import csv\n",
        "from itertools import islice\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import os\n",
        "import json, pickle\n",
        "from collections import OrderedDict\n",
        "import time\n",
        "\n",
        "import networkx as nx\n",
        "import sys\n",
        "\n",
        "sys.path.append('/content/DrugCombination')\n",
        "from src.utils.preprocessing import ExpressionEncoder, ConcentrationEncoder, SmilesEncoder\n",
        "from src.utils.data import *\n",
        "\n",
        "#from torch_geometric.nn.conv.gcn_conv import GCNConv\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.nn import Sequential, Linear, ReLU\n",
        "from torch_geometric.nn import GATConv, DenseGCNConv, GCNConv\n",
        "from torch_geometric.nn import DMoNPooling\n",
        "from torch_geometric.utils import to_dense_adj, to_dense_batch\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from typing import Optional\n",
        "import random\n",
        "\n",
        "from datetime import date\n",
        "\n",
        "# Change data and model root dir as you please\n",
        "data_dir = '/content/drive/MyDrive/Drugs/Data/polished'\n",
        "models_dir = '/content/drive/MyDrive/Drugs/models'\n",
        "\n",
        "torch.manual_seed(1401)\n",
        "\n",
        "%load_ext autoreload\n",
        "%autoreload 2\n",
        "%reload_ext autoreload"
      ],
      "metadata": {
        "id": "FiLPIwzQVdvL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b69a576a-2b9d-42d8-9b4b-f9a1e88f5738"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The autoreload extension is already loaded. To reload it, use:\n",
            "  %reload_ext autoreload\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Find an encoding for the gene expressions"
      ],
      "metadata": {
        "id": "mY6SrXrjcVBC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load all the expression values present in the database to obtain the encoder\n",
        "\n",
        "with open(os.path.join(data_dir, 'ccle_to_lincs_expression.pkl'), 'rb') as f:\n",
        "  cell_to_expression = pickle.load(f)\n",
        "\n",
        "all_exps = []\n",
        "for v in cell_to_expression.values():\n",
        "  all_exps.append(v[1])\n",
        "all_exps = np.array(all_exps, dtype=np.float32).reshape(-1)\n",
        "plt.hist(np.log(all_exps[all_exps > 0]), bins=30)\n",
        "plt.show()\n",
        "exp_encoder = ExpressionEncoder(all_exps)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "id": "57JOkhKIZORt",
        "outputId": "3b85afe7-cf35-4615-84ef-d26461d528a2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "exp_encoder.encode(22.5)"
      ],
      "metadata": {
        "id": "zq5JDjtl6nyi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Find an encoding for the concentrations\n"
      ],
      "metadata": {
        "id": "OiWd92Rxj0k4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv( os.path.join(data_dir, 'clean_combo_ONEIL_ALMANAC.csv'), index_col=[0])\n",
        "all_concs = np.array(list(df['ConcRow'].unique()) + list(df['ConcCol'].unique()))\n",
        "del df"
      ],
      "metadata": {
        "id": "RSVzYq0-j3f1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "conc_enc = ConcentrationEncoder(all_concs)\n",
        "conc_enc.encode(12)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zfGAMxcUoXn9",
        "outputId": "f46a4b95-56e1-4af2-e65e-3b140bf5a3bb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "       0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.,\n",
              "       0., 0., 0., 0., 0., 0., 0.], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Creating a pytorch standard dataset"
      ],
      "metadata": {
        "id": "DQv_tz6-VFXC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pickle\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from typing import List\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "from src.utils.preprocessing import ConcentrationEncoder, ExpressionEncoder, SmilesEncoder\n",
        "\n",
        "\n",
        "class ComboStatistics:\n",
        "  def __init__(self,\n",
        "               drug_rows,\n",
        "               drug_cols,\n",
        "               cells,\n",
        "               all_drugs,\n",
        "               drug_combs,\n",
        "               combinations):\n",
        "    self.drug_rows = drug_rows\n",
        "    self.drug_cols = drug_cols\n",
        "    self.cells = cells\n",
        "    self.all_drugs = all_drugs\n",
        "    self.combinations = combinations\n",
        "    self.drug_combs = drug_combs\n",
        "  \n",
        "  def __str__(self):\n",
        "    return f\"\"\"\n",
        "    number of drug rows : {len(self.drug_rows)}\n",
        "    number of drug columns : {len(self.drug_cols)}\n",
        "    number of all drugs : {len(self.all_drugs)}\n",
        "    number of cells : {len(self.cells)}\n",
        "    number of drug pair combinations : {len(self.drug_combs)}\n",
        "    number of drug drug cell combinations : {len(self.combinations)}\n",
        "    average screening per combination : {sum(list(self.combinations['size'])) / len(self.combinations)}\n",
        "    \"\"\"\n",
        "\n",
        "class ComboObject:\n",
        "    def __init__(self,\n",
        "                 graphs,\n",
        "                 concentrations,\n",
        "                 expression_profile,\n",
        "                 cell_id,\n",
        "                 drug_smiles1,\n",
        "                 drug_smiles2,\n",
        "                 concentrations_raw):\n",
        "        self.graphs = graphs\n",
        "        self.concentrations = concentrations\n",
        "        self.expression_profile = expression_profile\n",
        "        self.cell_id = cell_id\n",
        "        self.drug_smiles1 = drug_smiles1\n",
        "        self.drug_smiles2 = drug_smiles2\n",
        "        self.concentrations_raw = concentrations_raw\n",
        "\n",
        "class DrugComboDataSet(Dataset):\n",
        "    def __init__(self, *,\n",
        "                 dataframe: pd.DataFrame = None,\n",
        "                 combopath: str,\n",
        "                 sources: List[str],\n",
        "                 ccle_to_lincs_expression: str,\n",
        "                 gene_embedding_mapping: str = None):\n",
        "        \n",
        "        # Get the dataframe\n",
        "        if dataframe is not None:\n",
        "            self.all_combo_df = dataframe\n",
        "        else:\n",
        "            self.all_combo_df = pd.read_csv(combopath, index_col=[0], low_memory=False)\n",
        "\n",
        "        all_concs = np.array(list(self.all_combo_df['ConcRow'].unique()) + \\\n",
        "                             list(self.all_combo_df['ConcCol'].unique()))\n",
        "        self.concentration_encoder = ConcentrationEncoder(all_concs)\n",
        "        \n",
        "\n",
        "        # Filter out sources\n",
        "        self.all_combo_df = self.all_combo_df[self.all_combo_df.study_name.isin(sources)]\n",
        "\n",
        "        # Create a mapping from smiles to graph\n",
        "        smiles_encoder = SmilesEncoder()\n",
        "        self.map_smiles_to_graph = {}\n",
        "        for s1, s2 in zip(self.all_combo_df['SMILES1'], self.all_combo_df['SMILES2']):\n",
        "            try:\n",
        "                if s1 not in self.map_smiles_to_graph:\n",
        "                    self.map_smiles_to_graph[s1] = smiles_encoder.encode(s1)\n",
        "                if s2 not in self.map_smiles_to_graph:\n",
        "                    self.map_smiles_to_graph[s2] = smiles_encoder.encode(s2)\n",
        "            except Exception as e:\n",
        "                print(s1, s2)\n",
        "                raise Exception(f\"The smile string was not available for ({s1},{s2})!\")\n",
        "\n",
        "        # Get the mapping from cell id to expressions\n",
        "        with open(ccle_to_lincs_expression, 'rb') as f:\n",
        "            self.cell_to_expression = pickle.load(f)\n",
        "        all_exps = []\n",
        "        for v in self.cell_to_expression.values():\n",
        "            all_exps.append(v[1])\n",
        "        all_exps = np.array(all_exps, dtype=np.float32).reshape(-1)\n",
        "        expression_enc = ExpressionEncoder(all_exps)\n",
        "        \n",
        "        with open(gene_embedding_mapping, 'rb') as f:\n",
        "          self.tid_to_embedding = pickle.load(f)\n",
        "\n",
        "        # save all the mappings for faster processing time\n",
        "        self.id_to_expression_profile = {}\n",
        "        self.gene_vec = None\n",
        "        for k in self.cell_to_expression.keys():\n",
        "            tids = self.cell_to_expression[k][0]\n",
        "            perm = sorted(range(len(tids)), key=lambda i: tids[i])\n",
        "            v = self.cell_to_expression[k][1].astype(np.float32)[perm]\n",
        "            t = np.array([expression_enc.encode(exp) for exp in v], dtype=np.float32)\n",
        "            self.id_to_expression_profile[k] = t\n",
        "\n",
        "            if self.gene_vec is None:\n",
        "              self.gene_vec = np.array([self.tid_to_embedding[xt] \n",
        "                                        for xt in tids[perm]], dtype=np.float32)\n",
        "              self.gene_vec = torch.from_numpy(self.gene_vec)\n",
        "\n",
        "    def get_statistics(self, sub_indices):\n",
        "      ret = self.all_combo_df\n",
        "      ret['locations'] = list(range(len(self.all_combo_df)))\n",
        "      ret = ret[ret['locations'].isin(sub_indices)]\n",
        "      count_series_all = ret.groupby(['SMILES1', 'SMILES2', 'cell_ccle_id']).size()\n",
        "      count_series_all = count_series_all.to_frame(name = 'size').reset_index()\n",
        "\n",
        "      count_series_drugs = ret.groupby(['SMILES1', 'SMILES2']).size()\n",
        "      count_series_drugs = count_series_drugs.to_frame(name = 'size').reset_index()\n",
        "      return ComboStatistics(\n",
        "                      drug_rows=list(ret['SMILES1'].unique()),\n",
        "                      drug_cols=list(ret['SMILES2'].unique()),\n",
        "                      cells=list(ret['cell_ccle_id'].unique()),\n",
        "                      all_drugs = list(set(list(ret['SMILES1'].unique()) + list(ret['SMILES2'].unique()))),\n",
        "                      drug_combs = count_series_drugs,\n",
        "                      combinations = count_series_all)\n",
        "\n",
        "    def __getitem__(self, index: int):\n",
        "        val = self.all_combo_df.iloc[index]\n",
        "        g1 = self.map_smiles_to_graph[val['SMILES1']]\n",
        "        g2 = self.map_smiles_to_graph[val['SMILES2']]\n",
        "        c_raw1 = self.concentration_encoder.encode(val['ConcRow'])\n",
        "        c_raw2 = self.concentration_encoder.encode(val['ConcCol'])\n",
        "        c1 = torch.from_numpy(self.concentration_encoder.encode(val['ConcRow'])).float()\n",
        "        c2 = torch.from_numpy(self.concentration_encoder.encode(val['ConcCol'])).float()\n",
        "        exp_profile = torch.from_numpy(self.id_to_expression_profile[val['cell_ccle_id']]).float()\n",
        "        return ComboObject(graphs=[g1, g2],\n",
        "                           concentrations=[c1, c2],\n",
        "                           expression_profile=exp_profile,\n",
        "                           cell_id=val['cell_ccle_id'],\n",
        "                           drug_smiles1=val['SMILES1'],\n",
        "                           drug_smiles2=val['SMILES2'],\n",
        "                           concentrations_raw=[c_raw1, c_raw2]), \\\n",
        "               torch.from_numpy(np.array([val['Response']], dtype=np.float32))\n",
        "\n",
        "    def get_subset_indices(self, \n",
        "                           sources: List[str] = None,\n",
        "                           indices: List[int] = None,\n",
        "                           response_lt: float = None,\n",
        "                           response_gt: float = None,\n",
        "                           focus_drug_rows: List[str] = None,\n",
        "                           focus_drug_cols: List[str] = None,\n",
        "                           focus_cells: List[str] = None,\n",
        "                           screening_sample_ratio: float = None,\n",
        "                           screening_sample_count: int = None,\n",
        "                           verbose=0):\n",
        "        ret = self.all_combo_df\n",
        "        ret['locations'] = list(range(len(self.all_combo_df)))\n",
        "\n",
        "        # Find criterions and apply them\n",
        "        if sources is None:\n",
        "          sources = list(ret['study_name'].unique())\n",
        "        criterion = ret['study_name'].isin(sources)\n",
        "        if response_lt is not None:\n",
        "          criterion = criterion & (ret['Response'] <= response_lt)\n",
        "        if response_gt is not None:\n",
        "          criterion = criterion & (ret['Response'] >= response_gt)\n",
        "        if indices is not None:\n",
        "          criterion = criterion & ret['locations'].isin(indices)\n",
        "        if focus_drug_rows is not None:\n",
        "          criterion = criterion & ret['SMILES1'].isin(focus_drug_rows)\n",
        "        if focus_drug_cols is not None:\n",
        "          criterion = criterion & ret['SMILES2'].isin(focus_drug_cols)\n",
        "        if focus_cells is not None:\n",
        "          criterion = criterion & ret['cell_ccle_id'].isin(focus_cells)\n",
        "        ret = ret[criterion]\n",
        "        if verbose > 0:\n",
        "          print(\"Applied criterion\")\n",
        "\n",
        "        assert screening_sample_ratio is None or screening_sample_count is None, \\\n",
        "                \"screening sample ratio and screening sample count are mutually exclusive!\"\n",
        "        \n",
        "        # Randomly sample from screening\n",
        "        if screening_sample_ratio is not None:\n",
        "          ret = ret.groupby([\"SMILES1\", \"SMILES2\", \"cell_ccle_id\"]).sample(frac=screening_sample_ratio,\n",
        "                                                                          random_state=1)\n",
        "        if screening_sample_count is not None:\n",
        "          ret = ret.groupby([\"SMILES1\", \"SMILES2\", \"cell_ccle_id\"]).sample(n=screening_sample_count,\n",
        "                                                                          random_state=1, replace=True)\n",
        "        if verbose > 0:\n",
        "          print(\"Subsampling done!\")\n",
        "\n",
        "        ret = list(set(ret['locations']))\n",
        "        return ret\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.all_combo_df)\n",
        "\n",
        "\n",
        "class ComboBatchObject:\n",
        "    def __init__(self, graphs_x, edge_indices, batch_index,\n",
        "                 concentrations, cell_expression_profiles):\n",
        "        self.graphs_x = graphs_x\n",
        "        self.edge_indices = edge_indices\n",
        "        self.batch_index = batch_index\n",
        "        self.concentrations = concentrations\n",
        "        self.cell_expression_profiles = cell_expression_profiles\n",
        "\n",
        "\n",
        "def collate_drug_combo(batch):\n",
        "    all_batch = ComboBatchObject(graphs_x=[],\n",
        "                                 edge_indices=[],\n",
        "                                 batch_index=[],\n",
        "                                 concentrations=[],\n",
        "                                 cell_expression_profiles=None)\n",
        "\n",
        "    # number of combinations\n",
        "    N = None\n",
        "\n",
        "    accumulated_graphs = None\n",
        "    for batch_num, d in enumerate(batch):\n",
        "        graphs = d[0].graphs\n",
        "        N = len(graphs)\n",
        "\n",
        "        if accumulated_graphs is None:\n",
        "            accumulated_graphs = [{\n",
        "                'acc_nodes': 0,\n",
        "                'edge_index': [[], []],\n",
        "                'features': [],\n",
        "                'batch_index': []\n",
        "            } for _ in range(len(graphs))]\n",
        "            accumulated_nodes = np.zeros(len(graphs))\n",
        "\n",
        "        for i, g in enumerate(graphs):\n",
        "            c_size, features, edge_index = g\n",
        "            ad_val = accumulated_graphs[i]['acc_nodes']\n",
        "            for v1, v2 in edge_index:\n",
        "                accumulated_graphs[i]['edge_index'][0].append(ad_val + v1)\n",
        "                accumulated_graphs[i]['edge_index'][1].append(ad_val + v2)\n",
        "            accumulated_graphs[i]['features'] += features\n",
        "            accumulated_graphs[i]['acc_nodes'] += c_size\n",
        "            accumulated_graphs[i]['batch_index'] += (c_size * [batch_num])\n",
        "            #np.concatenate(accumulated_graphs[i]['batch_index'], batch_num * np.ones(c_size))\n",
        "\n",
        "    # Add the graph bits\n",
        "    for i in range(N):\n",
        "        all_batch.graphs_x.append(torch.from_numpy(np.array(accumulated_graphs[i]['features'], dtype=np.float32)))\n",
        "        tt = np.array(accumulated_graphs[i]['edge_index'], dtype=np.int64)\n",
        "        all_batch.edge_indices.append(\n",
        "            torch.from_numpy(tt)\n",
        "        )\n",
        "        all_batch.batch_index.append(\n",
        "            torch.from_numpy(np.array(accumulated_graphs[i]['batch_index'])))\n",
        "\n",
        "    # Add concentration embeddings\n",
        "    for i in range(N):\n",
        "        all_batch.concentrations.append(\n",
        "            torch.stack([b[0].concentrations[i] for b in batch])\n",
        "        )\n",
        "\n",
        "    all_batch.cell_expression_profiles = torch.stack([b[0].expression_profile for b in batch])\n",
        "\n",
        "    return all_batch, torch.stack([b[1] for b in batch])\n"
      ],
      "metadata": {
        "id": "wyIRKlIDhB1p"
      },
      "execution_count": 78,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Models"
      ],
      "metadata": {
        "id": "opdWBNS-DlcJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "You should embedd cells by considering their global pooling in 50 different aspects,"
      ],
      "metadata": {
        "id": "FKs2zY9RxZ26"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "class MoleculeEmbeddingNet(nn.Module):\n",
        "    def __init__(self, \n",
        "                 in_features : int =78, \n",
        "                 dropout : float =0.2, \n",
        "                 d_layers : List[int] = [128],\n",
        "                 layer_node_counts : List[int] = [20],\n",
        "                 first_layer_gnn_type : str = 'GAT',\n",
        "                 heads : Optional[int] = 10,\n",
        "                 has_pooling : bool = False):\n",
        "      \n",
        "        super(MoleculeEmbeddingNet, self).__init__()\n",
        "      \n",
        "        assert first_layer_gnn_type in ['GAT', 'GCN'], \\\n",
        "          f\"{first_layer_gnn_type} is not available in the supported first layers which are {['GAT', 'GCN']}\"\n",
        "\n",
        "        self.has_pooling = has_pooling\n",
        "        self.dropout_rate = dropout\n",
        "        self.d_layers = d_layers\n",
        "        self.layer_node_counts = layer_node_counts\n",
        "        self.first_layer_gnn_type = first_layer_gnn_type\n",
        "        self.heads = heads\n",
        "\n",
        "        # graph drug layers\n",
        "        cnt = 0\n",
        "        prv = in_features\n",
        "        for d, n_c in zip(d_layers, self.layer_node_counts):\n",
        "          cnt += 1\n",
        "          if cnt == 1:\n",
        "            if self.first_layer_gnn_type == 'GAT':\n",
        "              self.add_module('sparse_gnn_1', GATConv(prv, d, heads=self.heads))\n",
        "              self.add_module('sparse_gnn_2', GATConv(d * self.heads, d))\n",
        "              self.num_layer_first = 2\n",
        "            elif self.first_layer_gnn_type == 'GCN':\n",
        "              self.add_module('sparse_gnn_1', GCNConv(prv, d))\n",
        "              self.add_module('sparse_gnn_2', GCNConv(d, d))\n",
        "              self.add_module('sparse_gnn_3', GCNConv(d, d))\n",
        "              self.num_layer_first = 3\n",
        "          else:\n",
        "            self.add_module(f'gnn_{cnt}', DenseGCNConv(prv, d))\n",
        "\n",
        "          if self.has_pooling:\n",
        "            self.add_module(f'dmon_pooling_{cnt}', DMoNPooling([d, d], n_c))\n",
        "          prv = d\n",
        "        \n",
        "        self.out_features_dim = prv\n",
        "        \n",
        "\n",
        "    def forward(self, x, edge_index, batch):\n",
        "      for i in range(1, self.num_layer_first + 1):\n",
        "        L = self._modules[f'sparse_gnn_{i}']\n",
        "        x = L(x, edge_index)\n",
        "        x = F.elu(x)\n",
        "        x = F.dropout(x, p = self.dropout_rate, training=self.training)\n",
        "      cnt = 1\n",
        "      \n",
        "      x, mask = to_dense_batch(x, batch)\n",
        "      adj = to_dense_adj(edge_index, batch)\n",
        "      ret = 0\n",
        "      if self.has_pooling:\n",
        "        _, x, adj, sp1, o1, c1 = self._modules['dmon_pooling_1'](x, adj, mask)\n",
        "        ret += sp1 + o1 + c1\n",
        "      for cnt in range(2, len(self.d_layers) + 1):\n",
        "        L = self._modules[f'gnn_{cnt}']\n",
        "        x = L(x, adj)\n",
        "        x = F.elu(x)\n",
        "        # Could also add a dropout\n",
        "        if self.has_pooling:\n",
        "          _, x, adj, sp1, o1, c1 = self._modules[f'dmon_pooling_{cnt}'](x, adj)\n",
        "          ret += sp1 + o1 + c1\n",
        "      \n",
        "      return x, ret\n",
        "\n",
        "\n",
        "class CellEmbedder(nn.Module):\n",
        "  def __init__(self, dropout : float = 0.2,\n",
        "               out_features : int = 100):\n",
        "    super(CellEmbedder, self).__init__()\n",
        "    self.dropout_rate = dropout\n",
        "    self.out_features = out_features\n",
        "\n",
        " \n",
        "class CellEmbedderWithGeneVec(CellEmbedder):\n",
        "  def __init__(self, *,\n",
        "               dropout : float = 0.2,\n",
        "               expression_encoding_dim : int = 237,\n",
        "               gene_encoding_dim : int = 128,\n",
        "               k : int = 50, # The number of important genes that should be chosen\n",
        "               h : int = 2048,\n",
        "               gene_vec : torch.Tensor = None):\n",
        "    super(CellEmbedderWithGeneVec, self).__init__(dropout=dropout, out_features=gene_encoding_dim)\n",
        "\n",
        "    assert gene_vec != None, \"Cell embedder with gene vector defined but no mapping present!\"\n",
        "\n",
        "    self.exp_linear = nn.Linear(expression_encoding_dim, h)\n",
        "    self.gene_linear = nn.Linear(gene_encoding_dim, h)\n",
        "    self.k = k\n",
        "    self.gene_vec = gene_vec\n",
        "\n",
        "  def forward(self, expression_encodings):\n",
        "    \"\"\"\n",
        "    expression_encoding: B x (~1000) x expression_encoding_dim\n",
        "    gene_vecs: B x (~1000) x gene_encoding_dim\n",
        "    \"\"\"\n",
        "\n",
        "    B = expression_encodings.shape[0]\n",
        "  \n",
        "    I = self.exp_linear(expression_encodings)\n",
        "    I = F.elu(I)\n",
        "    K = self.gene_linear(self.gene_vec)\n",
        "    dots = torch.sum(I * K[None,:,:], axis = 2)\n",
        "    top = torch.topk(dots, self.k)\n",
        "    ret = torch.stack([vals[:,None] * self.gene_vec[ind] \n",
        "                       for ind, vals in zip(top.indices, top.values)])\n",
        "    return ret\n",
        "\n",
        "\n",
        "class CellEmbedderExpressionOnly(CellEmbedder):\n",
        "  # TODO: will implement this if with the embedding the model is still heavy \n",
        "  pass\n",
        "\n",
        "class TwoSidedAttentionModel(nn.Module):\n",
        "  def __init__(self, in_features_1 : int, in_features_2 : int, h : int = 2000, nheads : int=10):\n",
        "    super(TwoSidedAttentionModel, self).__init__()\n",
        "    \n",
        "    self.nheads = nheads\n",
        "    self.query = nn.Linear(in_features_1, h * nheads)\n",
        "    self.key = nn.Linear(in_features_2, h * nheads)\n",
        "    # for i in range(1, nheads + 1):\n",
        "    #   self.add_module(f'query_gen{i}', nn.Linear(in_features_1, h))\n",
        "    #   self.add_module(f'key_gen{i}', nn.Linear(in_features_2, h))\n",
        "  \n",
        "  def forward(self, x, y):\n",
        "    \"\"\"\n",
        "    x : [B x n_1 x in_features_1]\n",
        "    y : [B x n_2 x in_features_2]\n",
        "    \"\"\"\n",
        "    B = x.shape[0]\n",
        "    n1 = x.shape[1]\n",
        "    n2 = y.shape[1]\n",
        "    latent1 = self.query(x).reshape(B, n1, self.nheads, -1)\n",
        "    latent1 = F.elu(latent1)\n",
        "    latent2 = self.key(y).reshape(B, n2, self.nheads, -1)\n",
        "    latent1 = torch.transpose(latent1, 2, 1)\n",
        "    latent2 = torch.transpose(latent2, 2, 1)\n",
        "    dots = latent1 @ torch.transpose(latent2, 3, 2)\n",
        "    dots = dots.reshape(dots.shape[0], dots.shape[1], -1)\n",
        "    probs = F.softmax(dots, dim=1)\n",
        "    p1 = torch.repeat_interleave(x, y.shape[1], dim=1)\n",
        "    p2 = y.repeat(1, x.shape[1], 1)\n",
        "    all_concatenated = torch.cat([p1, p2], dim=2)\n",
        "    summed = torch.sum(probs[:,:,:,None] * all_concatenated[:,None,:,:], dim=2)\n",
        "    return summed.reshape(B, -1)\n",
        "\n",
        "class DrugDoseResponseModel(nn.Module):\n",
        "  def __init__(self,\n",
        "               molecule_embedding_net : MoleculeEmbeddingNet,\n",
        "               cell_embedding_net : CellEmbedder,\n",
        "               atom_conc_basis : int = 200,\n",
        "               concentration_in_features : int = 126,\n",
        "               nheads : int = 10,\n",
        "               h : int = 200,\n",
        "               dropout : float = 0.1\n",
        "               ):\n",
        "    super(DrugDoseResponseModel, self).__init__()\n",
        "    self.atom_to_key = nn.Linear(molecule_embedding_net.out_features_dim, atom_conc_basis)\n",
        "    self.concentration_to_key = nn.Linear(concentration_in_features, atom_conc_basis)\n",
        "    self.atom_to_value = nn.Linear(molecule_embedding_net.out_features_dim, atom_conc_basis)\n",
        "    self.cell_embedder2 = nn.Linear(cell_embedding_net.out_features, atom_conc_basis)\n",
        "    self.gnn_model = molecule_embedding_net\n",
        "    self.cell_embedder = cell_embedding_net\n",
        "    f1 = molecule_embedding_net.out_features_dim\n",
        "    f2 = cell_embedding_net.out_features\n",
        "    self.attention_model = TwoSidedAttentionModel(in_features_1=f1,\n",
        "                                                  in_features_2=f2,\n",
        "                                                  h = h,\n",
        "                                                  nheads = nheads)\n",
        "    \n",
        "    self.dropout_rate = dropout\n",
        "    self.linear1 = nn.Linear(nheads * (f1 + f2), 1000)\n",
        "    self.linear2 = nn.Linear(1000, 500)\n",
        "    self.linear3 = nn.Linear(500, 1)\n",
        "\n",
        "  def forward(self, x):\n",
        "    all_graphs_encoded = []\n",
        "    for g_x, g_edge_index, g_batch_index, conc in zip(x.graphs_x, x.edge_indices, x.batch_index, x.concentrations):\n",
        "      enc_features, _ = self.gnn_model(g_x, g_edge_index, g_batch_index)\n",
        "      K = self.atom_to_key(enc_features)\n",
        "      K = F.elu(K)\n",
        "      I = self.concentration_to_key(conc)\n",
        "      enriched = (K @ I.unsqueeze(2)) * enc_features\n",
        "      all_graphs_encoded.append(enriched)\n",
        "    drug = torch.cat(all_graphs_encoded, axis=1)\n",
        "    cell = self.cell_embedder(x.cell_expression_profiles)\n",
        "    combined = self.attention_model(drug, cell)\n",
        "    fwd = self.linear1(combined)\n",
        "    fwd = F.elu(fwd)\n",
        "    fwd = F.dropout(fwd, p=self.dropout_rate, training=self.training)\n",
        "    fwd = self.linear2(fwd)\n",
        "    fwd = F.elu(fwd)\n",
        "    fwd = F.dropout(fwd, p=self.dropout_rate, training=self.training)\n",
        "    return self.linear3(fwd)"
      ],
      "metadata": {
        "id": "gcahxmnrJKAv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Training core"
      ],
      "metadata": {
        "id": "UTWXURycJczZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Get the dataset\n",
        "\n",
        "dataset = DrugComboDataSet(\n",
        "    combopath = os.path.join(data_dir, 'clean_combo_ONEIL_ALMANAC.csv'),\n",
        "    sources = ['ALMANAC'],\n",
        "    ccle_to_lincs_expression = os.path.join(data_dir, 'ccle_to_lincs_expression.pkl'),\n",
        "    gene_embedding_mapping = os.path.join(data_dir, 'tid_to_gene_embedding.pkl')\n",
        ")"
      ],
      "metadata": {
        "id": "RVRKq-u2hEs9"
      },
      "execution_count": 79,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import Subset\n",
        "\n",
        "##################\n",
        "# (S1)\n",
        "# Filling in the gaps in partially measured doseâ€“response matrices\n",
        "##################\n",
        "\n",
        "# Find a training subset\n",
        "# This subset should not be super large and should represent the whole dataset\n",
        "# - discard data whose response are close to 100 and only let a few of them remain\n",
        "# - for each drug-cell combination, randomly sample 3-4 drug dose responses\n",
        "\n",
        "\n",
        "\n",
        "print(\"Coming up with a good training set!\")\n",
        "print(\"This might take a while ... \")\n",
        "\n",
        "sub1 = dataset.get_subset_indices(sources=['ALMANAC'],\n",
        "                                  response_lt=95,\n",
        "                                  screening_sample_count=3,\n",
        "                                  verbose=1\n",
        "                                  )\n",
        "sub2 = dataset.get_subset_indices(sources=['ALMANAC'],\n",
        "                                  screening_sample_count=3,\n",
        "                                  verbose=1,\n",
        "                                  response_lt=105)\n",
        "\n",
        "sub_mid = dataset.get_subset_indices(sources=['ALMANAC'],\n",
        "                                     response_lt=105,\n",
        "                                     screening_sample_count=3,\n",
        "                                     verbose=1,\n",
        "                                     response_gt=95)\n",
        "sub_mid = random.sample(sub_mid, int(0.05 * len(sub_mid)))\n",
        "\n",
        "sub_all = list(set(sub1 +  sub2 + sub_mid))\n",
        "\n",
        "sub_train = dataset.get_subset_indices(sources=['ALMANAC'],\n",
        "                                       screening_sample_ratio=0.5)\n",
        "sub_test = list(set(sub_all).difference(set(sub_train)))\n",
        "sub_val = dataset.get_subset_indices(indices=sub_train,\n",
        "                                     sources=['ALMANAC'],\n",
        "                                     screening_sample_ratio=0.1)\n",
        "sub_val = random.sample(sub_val, int(0.05 * len(sub_val)))\n",
        "sub_train = list(set(sub_train).difference(set(sub_val)))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k4ZZXR3U7be6",
        "outputId": "a5c704cc-548f-46d0-8738-51bd03f890ea"
      },
      "execution_count": 80,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Coming up with a good training set!\n",
            "This might take a while ... \n",
            "Applied criterion\n",
            "Subsampling done!\n",
            "Applied criterion\n",
            "Subsampling done!\n",
            "Applied criterion\n",
            "Subsampling done!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "train_dataset = Subset(dataset, sub_train)\n",
        "val_dataset = Subset(dataset, sub_val)\n",
        "test_dataset = Subset(dataset, sub_test)\n",
        "print(\"The subset sizes from all data:\")\n",
        "print(f\"{len(train_dataset)}/{len(dataset)}\\t\\t{len(val_dataset)}/{len(dataset)}\\t\\t{len(test_dataset)}/{len(dataset)}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2RDsiSyk9A5G",
        "outputId": "f3a709d8-4a00-4060-a46e-aceb7b3b36f9"
      },
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The subset sizes from all data:\n",
            "1549273/3118032\t\t9743/3118032\t\t533865/3118032\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "with open(os.path.join(data_dir, 's1_train_indices.pkl'), 'wb') as f:\n",
        "  pickle.dump(sub_train, f)\n",
        "with open(os.path.join(data_dir, 's1_val_indices.pkl'), 'wb') as f:\n",
        "  pickle.dump(sub_val, f)\n",
        "with open(os.path.join(data_dir, 's1_test_indices.pkl'), 'wb') as f:\n",
        "  pickle.dump(sub_test, f)"
      ],
      "metadata": {
        "id": "TpQX39h20cAw"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with open(os.path.join(data_dir, 's1_train_indices.pkl'), 'rb') as f:\n",
        "  sub_train = pickle.load(f)\n",
        "with open(os.path.join(data_dir, 's1_val_indices.pkl'), 'rb') as f:\n",
        "  sub_val = pickle.load(f)\n",
        "with open(os.path.join(data_dir, 's1_test_indices.pkl'), 'rb') as f:\n",
        "  sub_test = pickle.load(f)"
      ],
      "metadata": {
        "id": "rJIBNLWV0w67"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "stat_train = dataset.get_statistics(sub2)\n",
        "print(stat_train)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HEHJucGCzdV3",
        "outputId": "fdb36d73-3c69-407f-f8d2-60f4f482235d"
      },
      "execution_count": 81,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "502620\n",
            "\n",
            "    number of drug rows : 101\n",
            "    number of drug columns : 100\n",
            "    number of all drugs : 101\n",
            "    number of cells : 47\n",
            "    number of drug pair combinations : 4117\n",
            "    number of drug drug cell combinations : 179713\n",
            "    average screening per combination : 2.7967926638584855\n",
            "    \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "focus_drugs = random.sample(list(stat_train.all_drugs), 20)\n",
        "focus_cells = random.sample(list(stat_train.cells), 20)\n",
        "sub_train = dataset.get_subset_indices(indices=sub_train,\n",
        "                                       focus_drug_rows=focus_drugs,\n",
        "                                       focus_drug_cols=focus_drugs,\n",
        "                                       focus_cells=focus_cells)"
      ],
      "metadata": {
        "id": "ZceAY7kY1Bqw"
      },
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "BATCH_SIZE = 40\n",
        "\n",
        "# train_sampler = SubsetRandomSampler(train_dataset)\n",
        "# val_sampler = SubsetRandomSampler(val_split)\n",
        "# test_sampler = SubsetRandomSampler(test_split)\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, collate_fn = collate_drug_combo, shuffle=True)\n",
        "test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE, collate_fn = collate_drug_combo, shuffle=True)\n",
        "val_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE, collate_fn = collate_drug_combo, shuffle=True)\n",
        "\n",
        "print(f\"Batch size: {BATCH_SIZE}\")\n",
        "print(f\"length of train: {len(train_loader)}\")\n",
        "print(f\"length of validation: {len(val_loader)}\")\n",
        "print(f\"length of test: {len(test_loader)}\")"
      ],
      "metadata": {
        "id": "wAZ8N_SHJd3X",
        "outputId": "1a018c60-3c3c-411e-8b3d-c9d165a24be8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Batch size: 40\n",
            "length of train: 654\n",
            "length of validation: 244\n",
            "length of test: 3491\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "mol_embedder = MoleculeEmbeddingNet()\n",
        "cell_embedder = CellEmbedderWithGeneVec(gene_vec=dataset.gene_vec)"
      ],
      "metadata": {
        "id": "IZRZdUEjYIgl"
      },
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ddrm = DrugDoseResponseModel(molecule_embedding_net=mol_embedder, cell_embedding_net = cell_embedder)\n",
        "loss_train_history = [[], []] # first is the iteration nunber and the second is the last loss on training\n",
        "loss_validation_history = [[], []] # first is the interation number and the second is loss on the validation set\n",
        "iteration_loss_history = [[], []]\n",
        "last_epoch = 0"
      ],
      "metadata": {
        "id": "f8mFOYnSMvPW"
      },
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "N_EPOCH = 50\n",
        "LR = 1e-4\n",
        "EPOCH_FREQ = 2\n",
        "INTERMEDIATE_FREQ = 10\n",
        "\n",
        "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
        "print(f\"device: {device}\")\n",
        "criterion = nn.MSELoss()\n",
        "optim = torch.optim.Adam(ddrm.parameters(), lr=LR)\n"
      ],
      "metadata": {
        "id": "WxBjHb2sLTnG",
        "outputId": "5b7b2860-2f44-4c07-d195-acc4abd2d961",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "device: cuda:0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Set to true if you wish to see validation results in the beginning\n",
        "# initiate = False\n",
        "# skip_first = True\n",
        "\n",
        "SAVE_FREQ = 1000\n",
        "alpha = 0.01\n",
        "for last_epoch in range(last_epoch + 1, N_EPOCH): \n",
        "  ddrm.eval()\n",
        "  clear_output(True)\n",
        "  print(\"\\nCalculating validation ...\")\n",
        "  with torch.no_grad():\n",
        "    all_losses = []\n",
        "    for i, batch in tqdm(list(enumerate(val_loader))):\n",
        "      combo, responses = batch\n",
        "      pred = ddrm(combo)\n",
        "      loss = criterion(pred, responses)\n",
        "      all_losses.append(loss.item())\n",
        "    mean_loss = sum(all_losses) / len(all_losses)\n",
        "    loss_validation_history[0].append(last_epoch)\n",
        "    loss_validation_history[1].append(mean_loss)\n",
        "  \n",
        "  clear_output(True)\n",
        "  plt.plot(loss_train_history[0], loss_train_history[1], label='training curve')\n",
        "  plt.plot(loss_validation_history[0], loss_validation_history[1], label='validation curve')\n",
        "  plt.title('Training and validation')\n",
        "  plt.xlabel('epoch')\n",
        "  plt.ylabel('loss')\n",
        "  plt.legend()\n",
        "  plt.show() \n",
        "  ddrm.train()\n",
        "\n",
        "  \n",
        "  for iter, sample_batch in enumerate(train_loader):\n",
        "    combo, responses = sample_batch\n",
        "\n",
        "    start_t = time.time()\n",
        "    optim.zero_grad()\n",
        "    pred = ddrm(combo)\n",
        "    loss = criterion(pred, responses)\n",
        "    \n",
        "    iteration_loss_history[0].append(len(iteration_loss_history[0]) + 1)\n",
        "    iteration_loss_history[1].append(loss.item())\n",
        "    # print(\"prediction\", pred)\n",
        "    # print(\"response\", responses)\n",
        "    # print(\"loss\",loss.item())\n",
        "    print(f\"-epoch: [{last_epoch}/{N_EPOCH}]\\t-iteration: [{iter}/{len(train_loader)}]\\t-loss: {round(loss.item(), 2)}\\t-duration {round(time.time() - start_t, 4)}\")\n",
        "    loss.backward()\n",
        "    optim.step()\n",
        "    if iter % INTERMEDIATE_FREQ == 0:\n",
        "      clear_output(True)\n",
        "      figure, axis = plt.subplots(1, 2)\n",
        "\n",
        "      axis[0, 0].plot(iteration_loss_history[0], iteration_loss_history[1])\n",
        "      axis[0, 0].title('Only training history')\n",
        "      axis[0, 0].xlabel('iteration')\n",
        "      axis[0, 0].ylabel('loss')\n",
        "\n",
        "      axis[0, 1].plot(loss_train_history[0], loss_train_history[1], label='training curve')\n",
        "      axis[0, 1].plot(loss_validation_history[0], loss_validation_history[1], label='validation curve')\n",
        "      axis[0, 1].title('Training and validation')\n",
        "      axis[0, 1].xlabel('epoch')\n",
        "      axis[0, 1].ylabel('loss')\n",
        "      axis[0, 1].legend()\n",
        "      plt.show() \n",
        "  \n",
        "    if iter % SAVE_FREQ == 0:\n",
        "      torch.save(ddrm, os.path.join(models_dir, f'model_checkpoint_epoch{last_epoch}_iteration{iter}.pth'))\n"
      ],
      "metadata": {
        "id": "rcBmilOWsIo_",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 867
        },
        "outputId": "e3b06cc8-9d04-4499-e066-332566ce032a"
      },
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-epoch: 1\t-iteration: [41/654]\t-loss: 966.53\t-duration 1.597\n",
            "-epoch: 1\t-iteration: [42/654]\t-loss: 557.43\t-duration 1.6483\n",
            "-epoch: 1\t-iteration: [43/654]\t-loss: 321.34\t-duration 1.639\n",
            "-epoch: 1\t-iteration: [44/654]\t-loss: 981.96\t-duration 1.4812\n",
            "-epoch: 1\t-iteration: [45/654]\t-loss: 719.21\t-duration 1.4596\n",
            "-epoch: 1\t-iteration: [46/654]\t-loss: 555.75\t-duration 1.682\n",
            "-epoch: 1\t-iteration: [47/654]\t-loss: 546.49\t-duration 1.6365\n",
            "-epoch: 1\t-iteration: [48/654]\t-loss: 712.6\t-duration 1.6171\n",
            "-epoch: 1\t-iteration: [49/654]\t-loss: 798.88\t-duration 1.6455\n",
            "-epoch: 1\t-iteration: [50/654]\t-loss: 551.7\t-duration 1.6318\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-52-ae717fbbbd1e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     47\u001b[0m     \u001b[0;31m# print(\"loss\",loss.item())\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"-epoch: {last_epoch}\\t-iteration: [{iter}/{len(train_loader)}]\\t-loss: {round(loss.item(), 2)}\\t-duration {round(time.time() - start_t, 4)}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 49\u001b[0;31m     \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     50\u001b[0m     \u001b[0moptim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0miter\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mINTERMEDIATE_FREQ\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/_tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    305\u001b[0m                 \u001b[0mcreate_graph\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    306\u001b[0m                 inputs=inputs)\n\u001b[0;32m--> 307\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    308\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    309\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    154\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[1;32m    155\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 156\u001b[0;31m         allow_unreachable=True, accumulate_grad=True)  # allow_unreachable flag\n\u001b[0m\u001b[1;32m    157\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    158\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Manually save the model\n",
        "mex = 0\n",
        "while os.path.exists(os.path.join(models_dir, f'manual_checkpoint-{date.today()}-{mex}.pth')):\n",
        "  mex += 1\n",
        "torch.save(ddrm, os.path.join(models_dir, f'manual_checkpoint-{date.today()}-{mex}.pth'))"
      ],
      "metadata": {
        "id": "ilLy8Ch3ViJM"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}