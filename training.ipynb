{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "training.ipynb",
      "provenance": [],
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/HamidrezaKmK/2times2048/blob/master/training.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Prerequisites"
      ],
      "metadata": {
        "id": "hJK52DMK62tQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Git\n",
        "# SETUP GIT\n",
        "!git clone https://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@github.com/HamidrezaKmK/DrugCombination\n",
        "\n",
        "# Uncomment to pull \n",
        "#%cd /content/DrugCombination\n",
        "#!git pull"
      ],
      "metadata": {
        "id": "1mcybFjg64AR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8a5e7fe5-b303-4989-b58f-8a6e1c5432ac"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'DrugCombination'...\n",
            "remote: Enumerating objects: 175, done.\u001b[K\n",
            "remote: Counting objects: 100% (175/175), done.\u001b[K\n",
            "remote: Compressing objects: 100% (155/155), done.\u001b[K\n",
            "remote: Total 175 (delta 77), reused 50 (delta 16), pack-reused 0\u001b[K\n",
            "Receiving objects: 100% (175/175), 2.66 MiB | 9.10 MiB/s, done.\n",
            "Resolving deltas: 100% (77/77), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KaD9gBg8VA9c",
        "outputId": "56b0a6af-fb4c-48db-db2b-cec8981d1eca",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "# Import drive \n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#!pip uninstall torch -y\n",
        "!pip install torch==1.10.0+cu111 -f https://download.pytorch.org/whl/cu111/torch_stable.html\n",
        "!pip install rdkit-pypi\n",
        "!pip install networkx\n",
        "!pip install --no-index torch-sparse -f https://pytorch-geometric.com/whl/torch-1.10.0+cu111.html\n",
        "!pip install --no-index torch-cluster -f https://pytorch-geometric.com/whl/torch-1.10.0+cu111.html\n",
        "!pip install --no-index torch-spline-conv -f https://pytorch-geometric.com/whl/torch-1.10.0+cu111.html\n",
        "!pip install --no-index torch-scatter -f https://pytorch-geometric.com/whl/torch-1.10.0+cu111.html\n",
        "!pip install torch-geometric\n",
        "!pip install class-resolver"
      ],
      "metadata": {
        "id": "PG5l8cSUc_Yr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!nvidia-smi"
      ],
      "metadata": {
        "id": "QKUPeoTUBcBX",
        "outputId": "2e58ae50-d94a-4746-8c52-fa8e1c95db19",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sat May 21 06:47:06 2022       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 460.32.03    Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla P100-PCIE...  Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   41C    P0    27W / 250W |      2MiB / 16280MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tqdm import tqdm\n",
        "import pickle\n",
        "import pandas as pd\n",
        "import os\n",
        "import numpy as np\n",
        "from IPython.display import clear_output\n",
        "import math\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from typing import List\n",
        "from torch.utils.data import Dataset, DataLoader, SubsetRandomSampler\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import csv\n",
        "from itertools import islice\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import os\n",
        "import json, pickle\n",
        "from collections import OrderedDict\n",
        "import time\n",
        "\n",
        "import networkx as nx\n",
        "import sys\n",
        "\n",
        "sys.path.append('/content/DrugCombination')\n",
        "from src.utils.preprocessing import ExpressionEncoder, ConcentrationEncoder, SmilesEncoder\n",
        "from src.utils.data import *\n",
        "\n",
        "#from torch_geometric.nn.conv.gcn_conv import GCNConv\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.nn import Sequential, Linear, ReLU\n",
        "from torch_geometric.nn import GATConv, DenseGCNConv, GCNConv\n",
        "from torch_geometric.nn import DMoNPooling\n",
        "from torch_geometric.utils import to_dense_adj, to_dense_batch\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from typing import Optional\n",
        "\n",
        "from datetime import date\n",
        "\n",
        "# Change data and model root dir as you please\n",
        "data_dir = '/content/drive/MyDrive/Drugs/Data/polished'\n",
        "models_dir = '/content/drive/MyDrive/Drugs/models'\n",
        "\n",
        "torch.manual_seed(1401)\n",
        "\n",
        "%load_ext autoreload\n",
        "%autoreload 2\n",
        "%reload_ext autoreload"
      ],
      "metadata": {
        "id": "FiLPIwzQVdvL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Find an encoding for the gene expressions"
      ],
      "metadata": {
        "id": "mY6SrXrjcVBC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load all the expression values present in the database to obtain the encoder\n",
        "\n",
        "with open(os.path.join(data_dir, 'ccle_to_lincs_expression.pkl'), 'rb') as f:\n",
        "  cell_to_expression = pickle.load(f)\n",
        "\n",
        "all_exps = []\n",
        "for v in cell_to_expression.values():\n",
        "  all_exps.append(v[1])\n",
        "all_exps = np.array(all_exps, dtype=np.float32).reshape(-1)\n",
        "plt.hist(np.log(all_exps[all_exps > 0]), bins=30)\n",
        "plt.show()\n",
        "exp_encoder = ExpressionEncoder(all_exps)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "id": "57JOkhKIZORt",
        "outputId": "3b85afe7-cf35-4615-84ef-d26461d528a2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "exp_encoder.encode(22.5)"
      ],
      "metadata": {
        "id": "zq5JDjtl6nyi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Find an encoding for the concentrations\n"
      ],
      "metadata": {
        "id": "OiWd92Rxj0k4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv( os.path.join(data_dir, 'clean_combo_ONEIL_ALMANAC.csv'), index_col=[0])\n",
        "all_concs = np.array(list(df['ConcRow'].unique()) + list(df['ConcCol'].unique()))\n",
        "del df"
      ],
      "metadata": {
        "id": "RSVzYq0-j3f1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "conc_enc = ConcentrationEncoder(all_concs)\n",
        "conc_enc.encode(12)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zfGAMxcUoXn9",
        "outputId": "f46a4b95-56e1-4af2-e65e-3b140bf5a3bb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "       0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.,\n",
              "       0., 0., 0., 0., 0., 0., 0.], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Creating a pytorch standard dataset"
      ],
      "metadata": {
        "id": "DQv_tz6-VFXC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import Subset\n",
        "\n",
        "subset_ind = dataset.get_subset_indices(indices=[1, 10, 11, 20])\n",
        "print(\"Done here\")\n",
        "sub_dataset = Subset(dataset, subset_ind)\n",
        "print(len(sub_dataset))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k4ZZXR3U7be6",
        "outputId": "ea379fa2-d60c-4a9c-a9ae-d149af6d0985"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Done here\n",
            "4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pickle\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from typing import List\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "from src.utils.preprocessing import ConcentrationEncoder, ExpressionEncoder, SmilesEncoder\n",
        "\n",
        "\n",
        "class ComboObject:\n",
        "    def __init__(self,\n",
        "                 graphs,\n",
        "                 concentrations,\n",
        "                 expression_profile,\n",
        "                 cell_id):\n",
        "        self.graphs = graphs\n",
        "        self.concentrations = concentrations\n",
        "        self.expression_profile = expression_profile\n",
        "        self.cell_id = cell_id\n",
        "\n",
        "class DrugComboDataSet(Dataset):\n",
        "    def __init__(self, *,\n",
        "                 dataframe: pd.DataFrame = None,\n",
        "                 combopath: str,\n",
        "                 sources: List[str],\n",
        "                 ccle_to_lincs_expression: str,\n",
        "                 gene_embedding_mapping: str = None):\n",
        "        \n",
        "        # Get the dataframe\n",
        "        if dataframe is not None:\n",
        "            self.all_combo_df = dataframe\n",
        "        else:\n",
        "            self.all_combo_df = pd.read_csv(combopath, index_col=[0], low_memory=False)\n",
        "        all_concs = np.array(list(self.all_combo_df['ConcRow'].unique()) + \\\n",
        "                             list(self.all_combo_df['ConcCol'].unique()))\n",
        "        self.concentration_encoder = ConcentrationEncoder(all_concs)\n",
        "\n",
        "        # Filter out sources\n",
        "        self.all_combo_df = self.all_combo_df[self.all_combo_df.study_name.isin(sources)]\n",
        "\n",
        "        # Create a mapping from smiles to graph\n",
        "        smiles_encoder = SmilesEncoder()\n",
        "        self.map_smiles_to_graph = {}\n",
        "        for s1, s2 in zip(self.all_combo_df['SMILES1'], self.all_combo_df['SMILES2']):\n",
        "            try:\n",
        "                if s1 not in self.map_smiles_to_graph:\n",
        "                    self.map_smiles_to_graph[s1] = smiles_encoder.encode(s1)\n",
        "                if s2 not in self.map_smiles_to_graph:\n",
        "                    self.map_smiles_to_graph[s2] = smiles_encoder.encode(s2)\n",
        "            except Exception as e:\n",
        "                print(s1, s2)\n",
        "                raise Exception(f\"The smile string was not available for ({s1},{s2})!\")\n",
        "\n",
        "        # Get the mapping from cell id to expressions\n",
        "        with open(ccle_to_lincs_expression, 'rb') as f:\n",
        "            self.cell_to_expression = pickle.load(f)\n",
        "        all_exps = []\n",
        "        for v in self.cell_to_expression.values():\n",
        "            all_exps.append(v[1])\n",
        "        all_exps = np.array(all_exps, dtype=np.float32).reshape(-1)\n",
        "        expression_enc = ExpressionEncoder(all_exps)\n",
        "        \n",
        "        with open(gene_embedding_mapping, 'rb') as f:\n",
        "          self.tid_to_embedding = pickle.load(f)\n",
        "\n",
        "        # save all the mappings for faster processing time\n",
        "        self.id_to_expression_profile = {}\n",
        "        self.gene_vec = None\n",
        "        for k in self.cell_to_expression.keys():\n",
        "            tids = self.cell_to_expression[k][0]\n",
        "            perm = sorted(range(len(tids)), key=lambda i: tids[i])\n",
        "            v = self.cell_to_expression[k][1].astype(np.float32)[perm]\n",
        "            t = np.array([expression_enc.encode(exp) for exp in v], dtype=np.float32)\n",
        "            self.id_to_expression_profile[k] = t\n",
        "\n",
        "            if self.gene_vec is None:\n",
        "              self.gene_vec = np.array([self.tid_to_embedding[xt] \n",
        "                                        for xt in tids[perm]], dtype=np.float32)\n",
        "              self.gene_vec = torch.from_numpy(self.gene_vec)\n",
        "\n",
        "    def __getitem__(self, index: int):\n",
        "        val = self.all_combo_df.iloc[index]\n",
        "        g1 = self.map_smiles_to_graph[val['SMILES1']]\n",
        "        g2 = self.map_smiles_to_graph[val['SMILES2']]\n",
        "        c1 = torch.from_numpy(self.concentration_encoder.encode(val['ConcRow'])).float()\n",
        "        c2 = torch.from_numpy(self.concentration_encoder.encode(val['ConcCol'])).float()\n",
        "        exp_profile = torch.from_numpy(self.id_to_expression_profile[val['cell_ccle_id']]).float()\n",
        "        return ComboObject(graphs=[g1, g2],\n",
        "                           concentrations=[c1, c2],\n",
        "                           expression_profile=exp_profile,\n",
        "                           cell_id=val['cell_ccle_id']), \\\n",
        "               torch.from_numpy(np.array([val['Response']], dtype=np.float32))\n",
        "\n",
        "    def get_subset_indices(self, sources: List[str] = None,\n",
        "                           indices: List[int] = None):\n",
        "        self.all_combo_df['locations'] = list(range(len(self.all_combo_df)))\n",
        "        if sources is None:\n",
        "            sources = list(self.all_combo_df['study_name'].unique())\n",
        "        criterion = self.all_combo_df['study_name'].isin(sources)\n",
        "        if indices is not None:\n",
        "            criterion = criterion & self.all_combo_df['locations'].isin(indices)\n",
        "        ret = list(self.all_combo_df[criterion]['locations'])\n",
        "        self.all_combo_df = self.all_combo_df.drop(columns=['locations'])\n",
        "        return ret\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.all_combo_df)\n",
        "\n",
        "\n",
        "class ComboBatchObject:\n",
        "    def __init__(self, graphs_x, edge_indices, batch_index,\n",
        "                 concentrations, cell_expression_profiles, cell_ids):\n",
        "        self.graphs_x = graphs_x\n",
        "        self.edge_indices = edge_indices\n",
        "        self.batch_index = batch_index\n",
        "        self.concentrations = concentrations\n",
        "        self.cell_expression_profiles = cell_expression_profiles\n",
        "        self.cell_ids = cell_ids\n",
        "\n",
        "\n",
        "def collate_drug_combo(batch):\n",
        "    all_batch = ComboBatchObject(graphs_x=[],\n",
        "                                 edge_indices=[],\n",
        "                                 batch_index=[],\n",
        "                                 concentrations=[],\n",
        "                                 cell_expression_profiles=None,\n",
        "                                 cell_ids=None)\n",
        "\n",
        "    # number of combinations\n",
        "    N = None\n",
        "\n",
        "    accumulated_graphs = None\n",
        "    for batch_num, d in enumerate(batch):\n",
        "        graphs = d[0].graphs\n",
        "        N = len(graphs)\n",
        "\n",
        "        if accumulated_graphs is None:\n",
        "            accumulated_graphs = [{\n",
        "                'acc_nodes': 0,\n",
        "                'edge_index': [[], []],\n",
        "                'features': [],\n",
        "                'batch_index': []\n",
        "            } for _ in range(len(graphs))]\n",
        "            accumulated_nodes = np.zeros(len(graphs))\n",
        "\n",
        "        for i, g in enumerate(graphs):\n",
        "            c_size, features, edge_index = g\n",
        "            ad_val = accumulated_graphs[i]['acc_nodes']\n",
        "            for v1, v2 in edge_index:\n",
        "                accumulated_graphs[i]['edge_index'][0].append(ad_val + v1)\n",
        "                accumulated_graphs[i]['edge_index'][1].append(ad_val + v2)\n",
        "            accumulated_graphs[i]['features'] += features\n",
        "            accumulated_graphs[i]['acc_nodes'] += c_size\n",
        "            accumulated_graphs[i]['batch_index'] += (c_size * [batch_num])\n",
        "            #np.concatenate(accumulated_graphs[i]['batch_index'], batch_num * np.ones(c_size))\n",
        "\n",
        "    # Add the graph bits\n",
        "    for i in range(N):\n",
        "        all_batch.graphs_x.append(torch.from_numpy(np.array(accumulated_graphs[i]['features'], dtype=np.float32)))\n",
        "        tt = np.array(accumulated_graphs[i]['edge_index'], dtype=np.int64)\n",
        "        all_batch.edge_indices.append(\n",
        "            torch.from_numpy(tt)\n",
        "        )\n",
        "        all_batch.batch_index.append(\n",
        "            torch.from_numpy(np.array(accumulated_graphs[i]['batch_index'])))\n",
        "\n",
        "    # Add concentration embeddings\n",
        "    for i in range(N):\n",
        "        all_batch.concentrations.append(\n",
        "            torch.stack([b[0].concentrations[i] for b in batch])\n",
        "        )\n",
        "\n",
        "    all_batch.cell_expression_profiles = torch.stack([b[0].expression_profile for b in batch])\n",
        "    all_batch.cell_ids = [b[0].cell_id for b in batch]\n",
        "\n",
        "    return all_batch, torch.stack([b[1] for b in batch])\n"
      ],
      "metadata": {
        "id": "wyIRKlIDhB1p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Models"
      ],
      "metadata": {
        "id": "opdWBNS-DlcJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "You should embedd cells by considering their global pooling in 50 different aspects,"
      ],
      "metadata": {
        "id": "FKs2zY9RxZ26"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "class MoleculeEmbeddingNet(nn.Module):\n",
        "    def __init__(self, \n",
        "                 in_features : int =78, \n",
        "                 dropout : float =0.2, \n",
        "                 d_layers : List[int] = [128],\n",
        "                 layer_node_counts : List[int] = [20],\n",
        "                 first_layer_gnn_type : str = 'GAT',\n",
        "                 heads : Optional[int] = 10,\n",
        "                 has_pooling : bool = False):\n",
        "      \n",
        "        super(MoleculeEmbeddingNet, self).__init__()\n",
        "      \n",
        "        assert first_layer_gnn_type in ['GAT', 'GCN'], \\\n",
        "          f\"{first_layer_gnn_type} is not available in the supported first layers which are {['GAT', 'GCN']}\"\n",
        "\n",
        "        self.has_pooling = has_pooling\n",
        "        self.dropout_rate = dropout\n",
        "        self.d_layers = d_layers\n",
        "        self.layer_node_counts = layer_node_counts\n",
        "        self.first_layer_gnn_type = first_layer_gnn_type\n",
        "        self.heads = heads\n",
        "\n",
        "        # graph drug layers\n",
        "        cnt = 0\n",
        "        prv = in_features\n",
        "        for d, n_c in zip(d_layers, self.layer_node_counts):\n",
        "          cnt += 1\n",
        "          if cnt == 1:\n",
        "            if self.first_layer_gnn_type == 'GAT':\n",
        "              self.add_module('sparse_gnn_1', GATConv(prv, d, heads=self.heads))\n",
        "              self.add_module('sparse_gnn_2', GATConv(d * self.heads, d))\n",
        "              self.num_layer_first = 2\n",
        "            elif self.first_layer_gnn_type == 'GCN':\n",
        "              self.add_module('sparse_gnn_1', GCNConv(prv, d))\n",
        "              self.add_module('sparse_gnn_2', GCNConv(d, d))\n",
        "              self.add_module('sparse_gnn_3', GCNConv(d, d))\n",
        "              self.num_layer_first = 3\n",
        "          else:\n",
        "            self.add_module(f'gnn_{cnt}', DenseGCNConv(prv, d))\n",
        "\n",
        "          if self.has_pooling:\n",
        "            self.add_module(f'dmon_pooling_{cnt}', DMoNPooling([d, d], n_c))\n",
        "          prv = d\n",
        "        \n",
        "        self.out_features_dim = prv\n",
        "        \n",
        "\n",
        "    def forward(self, x, edge_index, batch):\n",
        "      for i in range(1, self.num_layer_first + 1):\n",
        "        L = self._modules[f'sparse_gnn_{i}']\n",
        "        x = L(x, edge_index)\n",
        "        x = F.elu(x)\n",
        "        x = F.dropout(x, p = self.dropout_rate, training=self.training)\n",
        "      cnt = 1\n",
        "      \n",
        "      x, mask = to_dense_batch(x, batch)\n",
        "      adj = to_dense_adj(edge_index, batch)\n",
        "      ret = 0\n",
        "      if self.has_pooling:\n",
        "        _, x, adj, sp1, o1, c1 = self._modules['dmon_pooling_1'](x, adj, mask)\n",
        "        ret += sp1 + o1 + c1\n",
        "      for cnt in range(2, len(self.d_layers) + 1):\n",
        "        L = self._modules[f'gnn_{cnt}']\n",
        "        x = L(x, adj)\n",
        "        x = F.elu(x)\n",
        "        # Could also add a dropout\n",
        "        if self.has_pooling:\n",
        "          _, x, adj, sp1, o1, c1 = self._modules[f'dmon_pooling_{cnt}'](x, adj)\n",
        "          ret += sp1 + o1 + c1\n",
        "      \n",
        "      return x, ret\n",
        "\n",
        "\n",
        "class CellEmbedder(nn.Module):\n",
        "  def __init__(self, dropout : float = 0.2,\n",
        "               out_features : int = 100):\n",
        "    super(CellEmbedder, self).__init__()\n",
        "    self.dropout_rate = dropout\n",
        "    self.out_features = out_features\n",
        "\n",
        " \n",
        "class CellEmbedderWithGeneVec(CellEmbedder):\n",
        "  def __init__(self, *,\n",
        "               dropout : float = 0.2,\n",
        "               expression_encoding_dim : int = 237,\n",
        "               gene_encoding_dim : int = 128,\n",
        "               k : int = 50, # The number of important genes that should be chosen\n",
        "               h : int = 2048,\n",
        "               gene_vec : torch.Tensor = None):\n",
        "    super(CellEmbedderWithGeneVec, self).__init__(dropout=dropout, out_features=gene_encoding_dim)\n",
        "\n",
        "    assert gene_vec != None, \"Cell embedder with gene vector defined but no mapping present!\"\n",
        "\n",
        "    self.exp_linear = nn.Linear(expression_encoding_dim, h)\n",
        "    self.gene_linear = nn.Linear(gene_encoding_dim, h)\n",
        "    self.k = k\n",
        "    self.gene_vec = gene_vec\n",
        "\n",
        "  def forward(self, expression_encodings):\n",
        "    \"\"\"\n",
        "    expression_encoding: B x (~1000) x expression_encoding_dim\n",
        "    gene_vecs: B x (~1000) x gene_encoding_dim\n",
        "    \"\"\"\n",
        "\n",
        "    B = expression_encodings.shape[0]\n",
        "  \n",
        "    I = self.exp_linear(expression_encodings)\n",
        "    I = F.elu(I)\n",
        "    K = self.gene_linear(self.gene_vec)\n",
        "    dots = torch.sum(I * K[None,:,:], axis = 2)\n",
        "    top = torch.topk(dots, self.k)\n",
        "    ret = torch.stack([vals[:,None] * self.gene_vec[ind] \n",
        "                       for ind, vals in zip(top.indices, top.values)])\n",
        "    return ret\n",
        "\n",
        "\n",
        "class CellEmbedderExpressionOnly(CellEmbedder):\n",
        "  # TODO: will implement this if with the embedding the model is still heavy \n",
        "  pass\n",
        "\n",
        "class TwoSidedAttentionModel(nn.Module):\n",
        "  def __init__(self, in_features_1 : int, in_features_2 : int, h : int = 2000, nheads : int=10):\n",
        "    super(TwoSidedAttentionModel, self).__init__()\n",
        "    \n",
        "    self.nheads = nheads\n",
        "    for i in range(1, nheads + 1):\n",
        "      self.add_module(f'query_gen{i}', nn.Linear(in_features_1, h))\n",
        "      self.add_module(f'key_gen{i}', nn.Linear(in_features_2, h))\n",
        "  \n",
        "  def forward(self, x, y):\n",
        "    \"\"\"\n",
        "    x : [B x n_1 x in_features_1]\n",
        "    y : [B x n_2 x in_features_2]\n",
        "    \"\"\"\n",
        "    #bef = time.time()\n",
        "    #TODO: make it faster!\n",
        "    all_heads = []\n",
        "    for i in range(1, self.nheads + 1):\n",
        "      latent1 = self._modules[f'query_gen{i}'](x)\n",
        "      latent1 = F.elu(latent1)\n",
        "      latent2 = self._modules[f'key_gen{i}'](y)\n",
        "      latent2 = F.elu(latent2)\n",
        "      dots = latent1 @ torch.transpose(latent2, 1, 2)\n",
        "      dots = dots.reshape(dots.shape[0], -1)\n",
        "      probs = F.softmax(dots, dim=1)\n",
        "      p1 = torch.repeat_interleave(x, y.shape[1], dim=1)\n",
        "      p2 = y.repeat(1, x.shape[1], 1)\n",
        "      all_concatenated = torch.cat([p1, p2], dim=2)\n",
        "      summed = torch.sum(probs[:,:,None] * all_concatenated, dim=1)\n",
        "      all_heads.append(summed)\n",
        "    #print(f\"\\nTime it took for the two sided attention {time.time() - bef}\")\n",
        "    return torch.cat(all_heads, dim=1)\n",
        "\n",
        "class DrugDoseResponseModel(nn.Module):\n",
        "  def __init__(self,\n",
        "               molecule_embedding_net : MoleculeEmbeddingNet,\n",
        "               cell_embedding_net : CellEmbedder,\n",
        "               atom_conc_basis : int = 200,\n",
        "               concentration_in_features : int = 126,\n",
        "               nheads : int = 10,\n",
        "               h : int = 200,\n",
        "               dropout : float = 0.1\n",
        "               ):\n",
        "    super(DrugDoseResponseModel, self).__init__()\n",
        "    self.atom_to_key = nn.Linear(molecule_embedding_net.out_features_dim, atom_conc_basis)\n",
        "    self.concentration_to_key = nn.Linear(concentration_in_features, atom_conc_basis)\n",
        "    self.atom_to_value = nn.Linear(molecule_embedding_net.out_features_dim, atom_conc_basis)\n",
        "    self.cell_embedder2 = nn.Linear(cell_embedding_net.out_features, atom_conc_basis)\n",
        "    self.gnn_model = molecule_embedding_net\n",
        "    self.cell_embedder = cell_embedding_net\n",
        "    f1 = molecule_embedding_net.out_features_dim\n",
        "    f2 = cell_embedding_net.out_features\n",
        "    self.attention_model = TwoSidedAttentionModel(in_features_1=f1,\n",
        "                                                  in_features_2=f2,\n",
        "                                                  h = h,\n",
        "                                                  nheads = nheads)\n",
        "    \n",
        "    self.dropout_rate = dropout\n",
        "    self.linear1 = nn.Linear(nheads * (f1 + f2), 1000)\n",
        "    self.linear2 = nn.Linear(1000, 500)\n",
        "    self.linear3 = nn.Linear(500, 1)\n",
        "\n",
        "  def forward(self, x):\n",
        "    all_graphs_encoded = []\n",
        "    for g_x, g_edge_index, g_batch_index, conc in zip(x.graphs_x, x.edge_indices, x.batch_index, x.concentrations):\n",
        "      enc_features, _ = self.gnn_model(g_x, g_edge_index, g_batch_index)\n",
        "      K = self.atom_to_key(enc_features)\n",
        "      K = F.elu(K)\n",
        "      I = self.concentration_to_key(conc)\n",
        "      I = F.elu(I)\n",
        "      enriched = (K @ I.unsqueeze(2)) * enc_features\n",
        "      all_graphs_encoded.append(enriched)\n",
        "    drug = torch.cat(all_graphs_encoded, axis=1)\n",
        "    cell = self.cell_embedder(x.cell_expression_profiles)\n",
        "    combined = self.attention_model(drug, cell)\n",
        "    fwd = self.linear1(combined)\n",
        "    fwd = F.elu(fwd)\n",
        "    fwd = F.dropout(fwd, p=self.dropout_rate, training=self.training)\n",
        "    fwd = self.linear2(fwd)\n",
        "    fwd = F.elu(fwd)\n",
        "    fwd = F.dropout(fwd, p=self.dropout_rate, training=self.training)\n",
        "    return self.linear3(fwd)"
      ],
      "metadata": {
        "id": "gcahxmnrJKAv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Training core"
      ],
      "metadata": {
        "id": "UTWXURycJczZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Get the dataset\n",
        "\n",
        "dataset = DrugComboDataSet(\n",
        "    combopath = os.path.join(data_dir, 'clean_combo_ONEIL_ALMANAC.csv'),\n",
        "    sources = ['ALMANAC'],\n",
        "    ccle_to_lincs_expression = os.path.join(data_dir, 'ccle_to_lincs_expression.pkl'),\n",
        "    gene_embedding_mapping = os.path.join(data_dir, 'tid_to_gene_embedding.pkl')\n",
        ")"
      ],
      "metadata": {
        "id": "RVRKq-u2hEs9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create the testing, validation and testing loader\n",
        "\n",
        "all_indices = list(range(len(dataset)))\n",
        "\n",
        "# Change params as you please\n",
        "test_split = 0.4\n",
        "validation_split = 0.000005\n",
        "train_split = 1 - (test_split + validation_split)\n",
        "BATCH_SIZE = 10\n",
        "\n",
        "train_sz = int(train_split * len(all_indices))\n",
        "test_sz = int(test_split * len(all_indices))\n",
        "\n",
        "np.random.shuffle(all_indices)\n",
        "\n",
        "train_split, test_split, val_split = all_indices[:train_sz], \\\n",
        "                                     all_indices[train_sz:test_sz + train_sz], \\\n",
        "                                     all_indices[test_sz + train_sz:]\n",
        "train_sampler = SubsetRandomSampler(train_split)\n",
        "val_sampler = SubsetRandomSampler(val_split)\n",
        "test_sampler = SubsetRandomSampler(test_split)\n",
        "\n",
        "train_loader = DataLoader(dataset, batch_size=BATCH_SIZE, collate_fn = collate_drug_combo, sampler=train_sampler)\n",
        "test_loader = DataLoader(dataset, batch_size=BATCH_SIZE, collate_fn = collate_drug_combo, sampler=test_sampler)\n",
        "val_loader = DataLoader(dataset, batch_size=BATCH_SIZE, collate_fn = collate_drug_combo, sampler=val_sampler)\n",
        "\n",
        "print(f\"Batch size: {BATCH_SIZE}\")\n",
        "print(f\"length of train: {len(train_loader)}\")\n",
        "print(f\"length of validation: {len(val_loader)}\")\n",
        "print(f\"length of test: {len(test_loader)}\")"
      ],
      "metadata": {
        "id": "wAZ8N_SHJd3X",
        "outputId": "4c3cad13-aa8e-4028-d118-59587548e173",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Batch size: 10\n",
            "length of train: 187081\n",
            "length of validation: 2\n",
            "length of test: 124722\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "mol_embedder = MoleculeEmbeddingNet()\n",
        "cell_embedder = CellEmbedderWithGeneVec(gene_vec=dataset.gene_vec)\n",
        "ddrm = DrugDoseResponseModel(molecule_embedding_net=mol_embedder, cell_embedding_net = cell_embedder)"
      ],
      "metadata": {
        "id": "f8mFOYnSMvPW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "N_EPOCH = 2000\n",
        "LR = 1e-6\n",
        "EPOCH_FREQ = 2\n",
        "INTERMEDIATE_FREQ = 10\n",
        "\n",
        "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
        "print(f\"device: {device}\")\n",
        "criterion = nn.MSELoss()\n",
        "optim = torch.optim.Adam(ddrm.parameters(), lr=LR)\n",
        "loss_train_history = [[], []] # first is the iteration nunber and the second is the last loss on training\n",
        "loss_validation_history = [[], []] # first is the interation number and the second is loss on the validation set\n",
        "last_epoch = 0"
      ],
      "metadata": {
        "id": "WxBjHb2sLTnG",
        "outputId": "fd354318-ca1f-4892-96d1-3f0b34dc1e24",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "device: cuda:0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Set to true if you wish to see validation results in the beginning\n",
        "initiate = True\n",
        "SAVE_FREQ = 1000\n",
        "for last_epoch in range(last_epoch + 1, N_EPOCH): \n",
        "  if initiate or last_epoch % EPOCH_FREQ == 0:\n",
        "    clear_output(True)\n",
        "    print(\"\\nCalculating validation ...\")\n",
        "    with torch.no_grad():\n",
        "      all_losses = []\n",
        "      for i, batch in tqdm(list(enumerate(val_loader))):\n",
        "        combo, responses = batch\n",
        "        pred = ddrm(combo)\n",
        "        loss = criterion(pred, responses)\n",
        "        all_losses.append(loss.item())\n",
        "      mean_loss = sum(all_losses) / len(all_losses)\n",
        "      loss_validation_history[0].append(len(loss_train_history[0]) + 1)\n",
        "      loss_validation_history[1].append(mean_loss)\n",
        "    \n",
        "    clear_output(True)\n",
        "    plt.plot(loss_train_history[0], loss_train_history[1], label='training curve')\n",
        "    plt.plot(loss_validation_history[0], loss_validation_history[1], label='validation curve')\n",
        "    plt.title('Training and validation')\n",
        "    plt.xlabel('iteration')\n",
        "    plt.ylabel('loss')\n",
        "    plt.legend()\n",
        "    plt.show() \n",
        "  initiate = False\n",
        "\n",
        "  for iter, sample_batch in enumerate(train_loader):\n",
        "    combo, responses = sample_batch\n",
        "\n",
        "    start_t = time.time()\n",
        "    optim.zero_grad()\n",
        "    pred = ddrm(combo)\n",
        "    loss = criterion(pred, responses)\n",
        "    \n",
        "    loss_train_history[0].append(len(loss_train_history[0]) + 1)\n",
        "    loss_train_history[1].append(loss.item())\n",
        "    # print(\"prediction\", pred)\n",
        "    # print(\"response\", responses)\n",
        "    # print(\"loss\",loss.item())\n",
        "    print(f\"-epoch: {last_epoch}\\t-iteration: [{iter}/{len(train_loader)}]\\t-loss: {round(loss.item(), 2)}\\t-duration {round(time.time() - start_t, 4)}\")\n",
        "    loss.backward()\n",
        "    optim.step()\n",
        "    if iter % INTERMEDIATE_FREQ == 0:\n",
        "      clear_output(True)\n",
        "      plt.plot(loss_train_history[0], loss_train_history[1])\n",
        "      plt.title('Only training history')\n",
        "      plt.xlabel('iteration')\n",
        "      plt.ylabel('loss')\n",
        "      plt.show()\n",
        "    \n",
        "    if iter % SAVE_FREQ == 0:\n",
        "      torch.save(ddrm, os.path.join(models_dir, f'model_checkpoint_epoch{last_epoch}_iteration{iter}.pth'))\n"
      ],
      "metadata": {
        "id": "rcBmilOWsIo_",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "0ec327a0-6d96-4001-9cd8-bf807862209e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Time it took for the two sided attention 0.5209171772003174\n",
            "-epoch: 1\t-iteration: [1/187081]\t-loss: 8107.4\t-duration 0.6559\n",
            "\n",
            "Time it took for the two sided attention 0.4569559097290039\n",
            "-epoch: 1\t-iteration: [2/187081]\t-loss: 6051.1\t-duration 0.5818\n",
            "\n",
            "Time it took for the two sided attention 0.4769327640533447\n",
            "-epoch: 1\t-iteration: [3/187081]\t-loss: 7331.94\t-duration 0.6195\n",
            "\n",
            "Time it took for the two sided attention 0.40526747703552246\n",
            "-epoch: 1\t-iteration: [4/187081]\t-loss: 8671.57\t-duration 0.5312\n",
            "\n",
            "Time it took for the two sided attention 0.39937758445739746\n",
            "-epoch: 1\t-iteration: [5/187081]\t-loss: 8444.49\t-duration 0.5485\n",
            "\n",
            "Time it took for the two sided attention 0.39728236198425293\n",
            "-epoch: 1\t-iteration: [6/187081]\t-loss: 6559.31\t-duration 0.5232\n",
            "\n",
            "Time it took for the two sided attention 0.40781712532043457\n",
            "-epoch: 1\t-iteration: [7/187081]\t-loss: 9156.64\t-duration 0.5354\n",
            "\n",
            "Time it took for the two sided attention 0.32523298263549805\n",
            "-epoch: 1\t-iteration: [8/187081]\t-loss: 8190.62\t-duration 0.4455\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-59-acf2115f2edb>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     32\u001b[0m     \u001b[0mstart_t\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m     \u001b[0moptim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 34\u001b[0;31m     \u001b[0mpred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mddrm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcombo\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     35\u001b[0m     \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresponses\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1102\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1103\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-56-d05868868144>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    192\u001b[0m     \u001b[0mdrug\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mall_graphs_encoded\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    193\u001b[0m     \u001b[0mcell\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcell_embedder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcell_expression_profiles\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 194\u001b[0;31m     \u001b[0mcombined\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mattention_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdrug\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcell\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    195\u001b[0m     \u001b[0mfwd\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcombined\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    196\u001b[0m     \u001b[0mfwd\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0melu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfwd\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1102\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1103\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-56-d05868868144>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x, y)\u001b[0m\n\u001b[1;32m    145\u001b[0m       \u001b[0mp1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrepeat_interleave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    146\u001b[0m       \u001b[0mp2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrepeat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 147\u001b[0;31m       \u001b[0mall_concatenated\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mp1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mp2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    148\u001b[0m       \u001b[0msummed\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprobs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mall_concatenated\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m       \u001b[0mall_heads\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msummed\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Manually save the model\n",
        "mex = 0\n",
        "while os.path.exists(os.path.join(models_dir, f'manual_checkpoint-{date.today()}-{mex}.pth')):\n",
        "  mex += 1\n",
        "torch.save(ddrm, os.path.join(models_dir, f'manual_checkpoint-{date.today()}-{mex}.pth'))"
      ],
      "metadata": {
        "id": "ilLy8Ch3ViJM"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}